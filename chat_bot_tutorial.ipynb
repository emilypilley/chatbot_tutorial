{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chat_bot_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fRwDaTb4A4Gv",
        "MjWgjFHA4672",
        "2GoBt0sP5PZ6",
        "r8eitZ72AvSp",
        "2wEIg6LkDA24",
        "uhn4M5bUCoJs",
        "iekew8D1Tcbp"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKyJTgBDk-a_"
      },
      "source": [
        "# Rule-Based Chatbot Tutorial\n",
        "* [Link to youtube playlist](https://youtu.be/RpWeNzfSUHw)\n",
        "* [Article with TF implementation](https://chatbotsmagazine.com/contextual-chat-bots-with-tensorflow-4391749d0077)\n",
        "\n",
        "**Overall Idea**: Our chatbot uses a model that is trained on cases of different intents (i.e. \"greeting\"), which is similar to a class label, and encompasses different patterns. There is a set of appropriate responses associated with each intent. \n",
        "\n",
        "However, you don't have to type the exact pattern in the training to get an appropriate response. The model predicts the intent of what the user wrote, and replies with an appropriate response for that intent. So, the chatbot can respond to whatever use cases you train the model on, and to extend the abilities of this chatbot, the model must be trained on additional intents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRwDaTb4A4Gv"
      },
      "source": [
        "###Relevant Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QUlw29nkQl_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf02b089-6c3b-46d2-d356-a0fe01a20e44"
      },
      "source": [
        "from os import path\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x37BsJ_gk2DC"
      },
      "source": [
        "##  Step 1 - Data Processing Methods\n",
        "* Bag of words - the words from all the patterns are each represented by an inedex of a list (which contains all the words) and we represent each example patter in our training data as a vector (which contains indices for each word from the list) with 1's in the indices for words that are in this pattern and 0's in the indices for words that are not in this pattern\n",
        "\n",
        "How do we get this bag of words from the text of the patterns we write out? \n",
        "* tokenization - to split the text into individual words and punctuation\n",
        "* stemming - to get a general root of the word (ex: \"organize\", \"organizer\", and \"organizing\" all really mean the same thing)\n",
        "* We also want to make all the words lowercase and might want to get rid of punctuation too\n",
        "\n",
        "The NLTK library can help us do this!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJkQL_gmpgB0"
      },
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "def tokenize(sentence):\n",
        "  return nltk.word_tokenize(sentence)\n",
        "\n",
        "def stem(word):\n",
        "  return stemmer.stem(word.lower())\n",
        "\n",
        "def bag_of_words(tokenized_sentence, all_words):\n",
        "  tokenized_sentence = [stem(w) for w in tokenized_sentence]\n",
        "  bag = np.zeros(len(all_words), dtype=np.float32)\n",
        "\n",
        "  for idx, w in enumerate(all_words):\n",
        "    if w in tokenized_sentence:\n",
        "      bag[idx] = 1.0\n",
        "  \n",
        "  return bag"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqCrtgYLqaKw"
      },
      "source": [
        "### Examples of how these functions work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyHEAfaEqeTb",
        "outputId": "8bb51111-c25e-4045-f6ea-538d8dbc8234"
      },
      "source": [
        "sent_1 = \"Hi, nice to meet you! How are you doing?\"\n",
        "\n",
        "sent_1_tokenized = tokenize(sent_1)\n",
        "print(sent_1_tokenized)\n",
        "\n",
        "sent_1_stemmed = [stem(word) for word in sent_1_tokenized]\n",
        "print(sent_1_stemmed)\n",
        "\n",
        "# The words in the sentence above aren't very complicated,\n",
        "# so let's try another example to see how the stemmer works\n",
        "words_to_stem = ['organize', 'organizer', 'organizing'] \n",
        "stemmed_words = [stem(word) for word in words_to_stem]\n",
        "print(stemmed_words)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hi', ',', 'nice', 'to', 'meet', 'you', '!', 'How', 'are', 'you', 'doing', '?']\n",
            "['hi', ',', 'nice', 'to', 'meet', 'you', '!', 'how', 'are', 'you', 'do', '?']\n",
            "['organ', 'organ', 'organ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLRxgvlM98bQ"
      },
      "source": [
        "To test the bag_of_words function here, make sure you don't use punctuation and that the words in your sentence are in the word set. This is just for the example - these cases will be handled properly when we make the chatbot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgdPlGJc94ii",
        "outputId": "46122536-929c-4038-c025-bba5a05e2610"
      },
      "source": [
        "word_set = ['hi', 'hello', 'i', 'you', 'me', 'good', 'bad', 'nice', 'to', 'am', 'are', 'meet', 'do', 'it', 'when', 'how']\n",
        "sent_1_no_punc = \"Hi nice to meet you How are you doing\"\n",
        "\n",
        "sent_1_no_punc_tokenized = tokenize(sent_1_no_punc)\n",
        "sent_1_no_punc_stemmed = [stem(word) for word in sent_1_no_punc_tokenized]\n",
        "\n",
        "bag = bag_of_words(sent_1_no_punc_tokenized, word_set)\n",
        "print(bag)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQhsypFnsOP3"
      },
      "source": [
        "###**TODO:** Try adding your own sentence(s) and see how it is processed\n",
        "Add your text in parentheses and set it equal to \"sent_2\", and then run the cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kisSmJp2sMf3",
        "outputId": "5b448ab4-3926-4b28-c902-9a5b61200e93"
      },
      "source": [
        "sent_2 = \"Remove this text and add your own!\"\n",
        "\n",
        "sent_2_tokenized = tokenize(sent_2)\n",
        "print(sent_2_tokenized)\n",
        "\n",
        "sent_2_stemmed = [stem(word) for word in sent_2_tokenized]\n",
        "print(sent_2_stemmed)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Remove', 'this', 'text', 'and', 'add', 'your', 'own', '!']\n",
            "['remov', 'thi', 'text', 'and', 'add', 'your', 'own', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dYh32wQr433"
      },
      "source": [
        "##Step 2 - Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjWgjFHA4672"
      },
      "source": [
        "### Loading the Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWTx4ZWbBPL1"
      },
      "source": [
        "First we get a premade JSON file with some intents, patterns, and responses predefined"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRGMlNpN25cZ"
      },
      "source": [
        "if not path.exists('chatbot_tutorial'):\n",
        "  !git clone https://github.com/emilypilley/chatbot_tutorial.git"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKdfY39C3dZz",
        "outputId": "25a08028-a2c0-4d68-ffd3-063406e56f75"
      },
      "source": [
        "!ls chatbot_tutorial/"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chat_bot_tutorial.ipynb  intents.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-1g13Hfr9ju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30ed72de-8980-4fba-9a68-5dafeba237f6"
      },
      "source": [
        "# This opens the json file with our intents\n",
        "with open('chatbot_tutorial/intents.json') as f:\n",
        "  intents = json.load(f)\n",
        "\n",
        "print(intents)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'intents': [{'tag': 'greeting', 'patterns': ['Hi', 'Hey', 'How are you', 'Is anyone there?', 'Hello', 'Good day'], 'responses': ['Hey :-)', 'Hello, thanks for visiting', 'Hi there, what can I do for you?', 'Hi there, how can I help?']}, {'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye'], 'responses': ['See you later, thanks for visiting', 'Have a nice day', 'Bye! Come back again soon.']}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", \"Thank's a lot!\"], 'responses': ['Happy to help!', 'Any time!', 'My pleasure']}, {'tag': 'items', 'patterns': ['Which items do you have?', 'What kinds of items are there?', 'What do you sell?'], 'responses': ['We sell coffee and tea', 'We have coffee and tea']}, {'tag': 'payments', 'patterns': ['Do you take credit cards?', 'Do you accept Mastercard?', 'Can I pay with Paypal?', 'Are you cash only?'], 'responses': ['We accept VISA, Mastercard and Paypal', 'We accept most major credit cards, and Paypal']}, {'tag': 'delivery', 'patterns': ['How long does delivery take?', 'How long does shipping take?', 'When do I get my delivery?'], 'responses': ['Delivery takes 2-4 days', 'Shipping takes 2-4 days']}, {'tag': 'funny', 'patterns': ['Tell me a joke!', 'Tell me something funny!', 'Do you know a joke?'], 'responses': ['Why did the hipster burn his mouth? He drank the coffee before it was cool.', 'What did the buffalo say when his son left for college? Bison.']}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GoBt0sP5PZ6"
      },
      "source": [
        "### Processing the Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy2f6Unt6s2j"
      },
      "source": [
        "First, we apply the stemming and tokenization to the patterns from the training data, and remove punctuation and duplicate items, to get a set of all the words used in each pattern. We associate all the patterns for one tag with that tag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkzj3hI64z0D"
      },
      "source": [
        "def process_training_data(intents):\n",
        "  all_words = []\n",
        "  tags = []\n",
        "  xy = []  # holds patterns (x) and their assoicated tags (y)\n",
        "\n",
        "  for intent in intents['intents']:\n",
        "    tag = intent['tag']\n",
        "    tags.append(tag)\n",
        "\n",
        "    for pattern in intent['patterns']:\n",
        "      w = tokenize(pattern)\n",
        "      all_words.extend(w)\n",
        "      xy.append((w, tag))\n",
        "\n",
        "  ignore_words = ['?', '!', '.', ',']\n",
        "  all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
        "  all_words = sorted(set(all_words))\n",
        "  # print(all_words)\n",
        "\n",
        "  tags = sorted(set(tags))\n",
        "  # print(tags)\n",
        "\n",
        "  return all_words, tags, xy\n",
        "\n",
        "all_words, tags, xy = process_training_data(intents)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8eitZ72AvSp"
      },
      "source": [
        "### Preparing the Training Data for use with PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7fdFkt975q6"
      },
      "source": [
        "Then, we separate the data into x (the patterns) and y (the tag for the patterns) in order to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ctx3-fO07TzG"
      },
      "source": [
        "def separate_train_x_y(all_words, tags, xy):\n",
        "  x_train = []  # holds the patterns\n",
        "  y_train = []  # holds the tags for each pattern\n",
        "\n",
        "  for (pattern_sentence, tag) in xy:\n",
        "    bag = bag_of_words(pattern_sentence, all_words)\n",
        "    x_train.append(bag)\n",
        "\n",
        "    label = tags.index(tag)  # for the labels we are storing a number representing the tag\n",
        "    y_train.append(label)\n",
        "\n",
        "  x_train = np.array(x_train)\n",
        "  y_train = np.array(y_train)\n",
        "\n",
        "  return x_train, y_train\n",
        "\n",
        "x_train, y_train = separate_train_x_y(all_words, tags, xy)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsZd3vDpGgJp",
        "outputId": "f0149c67-5cfc-41b0-c4d2-15d607757f92"
      },
      "source": [
        "# this is the first pattern and its associated tag in the training data\n",
        "print(x_train[0])\n",
        "print(y_train[0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0.]\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03iYXTC__LcJ"
      },
      "source": [
        "Here we turn the data into PyTorch datasets (for use with the model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baoEqVkm_R1S"
      },
      "source": [
        "class ChatDataset(Dataset):\n",
        "  def __init__(self, x_train, y_train):\n",
        "    self.n_samples = len(x_train)\n",
        "    self.x_data = x_train\n",
        "    self.y_data = y_train\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    return self.x_data[index], self.y_data[index]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.n_samples"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0G_h0hRC7Ov"
      },
      "source": [
        "### **TODO:** Set the Hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDKFdmvr_-zF"
      },
      "source": [
        "Hyperparameters are aspects of the model that we can change that impact training - you can try to change some of these and see how this affects the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLPGH8wz_90S"
      },
      "source": [
        "# You can try adjusing the following by changing the numbers\n",
        "batch_size = 8\n",
        "hidden_size = 8\n",
        "learning_rate = 0.001\n",
        "num_epochs = 1000"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaUwf_IlF06f",
        "outputId": "1d63e312-764e-4844-8cfb-6ddcca136828"
      },
      "source": [
        "# These depend on our particular data - don't change!\n",
        "output_size = len(tags)\n",
        "input_size = len(x_train[0])\n",
        "\n",
        "print('output_size: ', output_size)\n",
        "print('input_size: ', input_size)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output_size:  7\n",
            "input_size:  54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wEIg6LkDA24"
      },
      "source": [
        "### Create the dataset and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeMTpvSj_x_2"
      },
      "source": [
        "dataset = ChatDataset(x_train, y_train)\n",
        "train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl3x2xGHGzGu",
        "outputId": "0c4225d0-426d-45cd-e34d-260350c2322f"
      },
      "source": [
        "dataset.__getitem__(0)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0.], dtype=float32), 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dJAbqXxAgaH"
      },
      "source": [
        "## Step 3 - Create the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhn4M5bUCoJs"
      },
      "source": [
        "### Define the structure and flow of data through the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi-zEPmyAnVF"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  \n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet, self).__init__()\n",
        "\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.l2 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.l3 = nn.Linear(hidden_size, num_classes)\n",
        "    \n",
        "    self.relu = nn.ReLU()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    out = self.l2(out)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    out = self.l3(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUAYyaxgCip0"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = NeuralNet(input_size, hidden_size, output_size).to(device)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNDkFqqTEV70"
      },
      "source": [
        "Set loss function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D7cqfDsEUJQ"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_tX2DKjHpNS"
      },
      "source": [
        "###Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDd9FPxeEteL"
      },
      "source": [
        "Train the model to predict the tag based on the given input text (the patterns). This might take a minute, but you should be able to see the loss printed out after 100 epochs of training. Observe the loss function - it should be decreasing, indicating that the model is leraning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjxvQUSbEx9W",
        "outputId": "39961329-bd01-4f48-a616-339dce2e690a"
      },
      "source": [
        "def train_model(model, train_loader, loss_func, optimizer):\n",
        "  # training loop\n",
        "  for epoch in range(num_epochs):\n",
        "    for (words, labels) in train_loader:\n",
        "      words = words.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # forward pass\n",
        "      outputs = model(words)  # the outputs are the model's predictions\n",
        "      loss = loss_func(outputs, labels)\n",
        "\n",
        "      # backward and optimizer steps\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    \n",
        "    if (epoch + 1) % 100 == 0:\n",
        "      print(f'epoch {epoch+1}/{num_epochs}, loss={loss.item():.4f}')\n",
        "\n",
        "  print(f'final loss={loss.item():.4f}')\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "train_model(model, train_loader, criterion, optimizer)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 100/1000, loss=1.4775\n",
            "epoch 200/1000, loss=0.1640\n",
            "epoch 300/1000, loss=0.0410\n",
            "epoch 400/1000, loss=0.0351\n",
            "epoch 500/1000, loss=0.0178\n",
            "epoch 600/1000, loss=0.0016\n",
            "epoch 700/1000, loss=0.0027\n",
            "epoch 800/1000, loss=0.0005\n",
            "epoch 900/1000, loss=0.0003\n",
            "epoch 1000/1000, loss=0.0010\n",
            "final loss=0.0010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWgukQ52H9BT"
      },
      "source": [
        "## Step 4 - Use Model and Implement Chatting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9upzO1tuLHu3"
      },
      "source": [
        "### Implement the Chatting Functionality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC6zF41QLLnn"
      },
      "source": [
        "def run_chatbot(bot_name='Chatty'):\n",
        "  print(\"Let's chat! Type 'quit' to exit\")\n",
        "\n",
        "  while True:\n",
        "    sentence = input('You: ')\n",
        "\n",
        "    if sentence == 'quit':\n",
        "      break\n",
        "    \n",
        "    # process the sentence the user inputs\n",
        "    sentence = [stem(word) for word in tokenize(sentence)]\n",
        "    x = bag_of_words(sentence, all_words)\n",
        "\n",
        "    # reshape and format the input data for the model\n",
        "    x = x.reshape(1, x.shape[0])\n",
        "    x = torch.from_numpy(x)\n",
        "\n",
        "    # get the predicted tag from the model\n",
        "    output = model(x)\n",
        "    _, predicted = torch.max(output, dim=1)\n",
        "    # the model outputs a number for the tag, this coverts it to\n",
        "    # the actual name of the tag\n",
        "    tag = tags[predicted.item()] \n",
        "\n",
        "    # the model will tell us how likely it is that the input \n",
        "    # sentence corresponds to a certain tag\n",
        "    probabilities = torch.softmax(output, dim=1)\n",
        "    probability = probabilities[0][predicted.item()]\n",
        "    # print('tag: ', tag, ' probability: ', probability)  # for debugging\n",
        "    \n",
        "    if probability.item() > 0.75:\n",
        "      # find the corresponding intent for that tag\n",
        "      for intent in intents['intents']:\n",
        "        if tag == intent['tag']:\n",
        "          # the chatbot responds with one of the responses for \n",
        "          # the tag, randomly chosen from the possible responses\n",
        "          print(f\"{bot_name}: {random.choice(intent['responses'])}\") \n",
        "    \n",
        "    # if we couldn't determine what the intent of the sentence was \n",
        "    # with much certainty, the chatbot shouldn't respond\n",
        "    else:\n",
        "      print(f\"{bot_name}: I do not understand :(\") "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMtmZMo6IN6E",
        "outputId": "6d4e70e4-e402-439d-ee55-807a3521bae0"
      },
      "source": [
        "run_chatbot()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's chat! Type 'quit' to exit\n",
            "You: hello :)\n",
            "Chatty: Hello, thanks for visiting\n",
            "You: what do you seell?\n",
            "Chatty: We sell coffee and tea\n",
            "You: how long does delivery take?\n",
            "Chatty: Shipping takes 2-4 days\n",
            "You: do you take venmo?\n",
            "Chatty: I do not understand :(\n",
            "You: do you accept credit cards\n",
            "Chatty: We accept most major credit cards, and Paypal\n",
            "You: tell me a joke\n",
            "Chatty: Why did the hipster burn his mouth? He drank the coffee before it was cool.\n",
            "You: I hated your tea\n",
            "Chatty: I do not understand :(\n",
            "You: the coffee I got was gross\n",
            "Chatty: I do not understand :(\n",
            "You: bye\n",
            "Chatty: Bye! Come back again soon.\n",
            "You: quit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yasE79fWEfRS"
      },
      "source": [
        "## Step 5 - Adding New Intents and Patterns to Improve the Chatbot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iekew8D1Tcbp"
      },
      "source": [
        "### Implementation of functions to update JSON with new intents, print intents, and remove intents (given tag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zscz1oVCKsSa"
      },
      "source": [
        "These are functions to add the new intent to the JSON file holding all of the tags, patterns, and responses for each intent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRpTT147EjkE"
      },
      "source": [
        "def write_json(data, filename='chatbot_tutorial/intents.json'):\n",
        "    with open(filename,'w') as f:\n",
        "        json.dump(data, f, indent=4)\n",
        "      \n",
        "      \n",
        "def add_new_intent(tag, patterns, responses, filename='chatbot_tutorial/intents.json'):\n",
        "  with open('chatbot_tutorial/intents.json') as f:\n",
        "    data = json.load(f)\n",
        "      \n",
        "    intents = data['intents']\n",
        "  \n",
        "    new_intent = {\n",
        "      \"tag\": tag,\n",
        "      \"patterns\": patterns,\n",
        "      \"responses\": responses\n",
        "    }\n",
        "  \n",
        "    intents.append(new_intent)\n",
        "      \n",
        "  write_json(data, filename)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ee_RstHK2qq"
      },
      "source": [
        "If you want to check what intents are in the JSON file currently, run this method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGX8kMFqHYXm"
      },
      "source": [
        "def print_intents(filename='chatbot_tutorial/intents.json'):\n",
        "  with open('chatbot_tutorial/intents.json') as f:\n",
        "      data = json.load(f)\n",
        "        \n",
        "      intents = data['intents']\n",
        "      for intent in intents:\n",
        "        print(intent)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZa_Z7GPNH8x"
      },
      "source": [
        "If you want to remove an intent, just provide the tag to this method to delete it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zDNyu5OLtQ3"
      },
      "source": [
        "def remove_intent_with_tag(tag, filename='chatbot_tutorial/intents.json'):\n",
        "    with open('chatbot_tutorial/intents.json') as f:\n",
        "      data = json.load(f)\n",
        "      intents = data['intents']\n",
        "      for intent in intents:\n",
        "        if intent['tag'] == tag:\n",
        "          intents.remove(intent)\n",
        "\n",
        "    write_json(data, filename)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVu5P-iFh7IU",
        "outputId": "8e830819-a105-4ece-9edf-d007c8b645e2"
      },
      "source": [
        "print_intents()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'tag': 'greeting', 'patterns': ['Hi', 'Hey', 'How are you', 'Is anyone there?', 'Hello', 'Good day'], 'responses': ['Hey :-)', 'Hello, thanks for visiting', 'Hi there, what can I do for you?', 'Hi there, how can I help?']}\n",
            "{'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye'], 'responses': ['See you later, thanks for visiting', 'Have a nice day', 'Bye! Come back again soon.']}\n",
            "{'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", \"Thank's a lot!\"], 'responses': ['Happy to help!', 'Any time!', 'My pleasure']}\n",
            "{'tag': 'items', 'patterns': ['Which items do you have?', 'What kinds of items are there?', 'What do you sell?'], 'responses': ['We sell coffee and tea', 'We have coffee and tea']}\n",
            "{'tag': 'payments', 'patterns': ['Do you take credit cards?', 'Do you accept Mastercard?', 'Can I pay with Paypal?', 'Are you cash only?'], 'responses': ['We accept VISA, Mastercard and Paypal', 'We accept most major credit cards, and Paypal']}\n",
            "{'tag': 'delivery', 'patterns': ['How long does delivery take?', 'How long does shipping take?', 'When do I get my delivery?'], 'responses': ['Delivery takes 2-4 days', 'Shipping takes 2-4 days']}\n",
            "{'tag': 'funny', 'patterns': ['Tell me a joke!', 'Tell me something funny!', 'Do you know a joke?'], 'responses': ['Why did the hipster burn his mouth? He drank the coffee before it was cool.', 'What did the buffalo say when his son left for college? Bison.']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nnpk9OwuKdwh"
      },
      "source": [
        "### **TODO:** Fill in the tag, patterns, and responses as shown below with your new intent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTYsw-bBJ1KN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "259e0ed5-9ee8-45bf-c6b4-9fe10a262abe"
      },
      "source": [
        "tag = \"complaint\"\n",
        "\n",
        "patterns = [\n",
        "            \"Your tea was awful\",\n",
        "            \"The coffee sucks\",\n",
        "            \"The tea I ordered was gross\",\n",
        "            \"I hated the coffee I bought from you\",\n",
        "            \"Your products are awful\",\n",
        "            \"Your store is terrible\",\n",
        "            \"The coffee I ordered tasted like garbage\"\n",
        "            ]\n",
        "\n",
        "responses =  [\n",
        "              \"I'm sorry you did not like our product.\",\n",
        "              \"I guess our store just isn't your cup of tea.\",\n",
        "              \"I'm sorry you had a bad experience.\"\n",
        "              ]\n",
        "\n",
        "# This method adds the new intent\n",
        "add_new_intent(tag, patterns, responses)\n",
        "\n",
        "# Print out the intents to see that the file was updated with the new data\n",
        "print_intents()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'tag': 'greeting', 'patterns': ['Hi', 'Hey', 'How are you', 'Is anyone there?', 'Hello', 'Good day'], 'responses': ['Hey :-)', 'Hello, thanks for visiting', 'Hi there, what can I do for you?', 'Hi there, how can I help?']}\n",
            "{'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye'], 'responses': ['See you later, thanks for visiting', 'Have a nice day', 'Bye! Come back again soon.']}\n",
            "{'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", \"Thank's a lot!\"], 'responses': ['Happy to help!', 'Any time!', 'My pleasure']}\n",
            "{'tag': 'items', 'patterns': ['Which items do you have?', 'What kinds of items are there?', 'What do you sell?'], 'responses': ['We sell coffee and tea', 'We have coffee and tea']}\n",
            "{'tag': 'payments', 'patterns': ['Do you take credit cards?', 'Do you accept Mastercard?', 'Can I pay with Paypal?', 'Are you cash only?'], 'responses': ['We accept VISA, Mastercard and Paypal', 'We accept most major credit cards, and Paypal']}\n",
            "{'tag': 'delivery', 'patterns': ['How long does delivery take?', 'How long does shipping take?', 'When do I get my delivery?'], 'responses': ['Delivery takes 2-4 days', 'Shipping takes 2-4 days']}\n",
            "{'tag': 'funny', 'patterns': ['Tell me a joke!', 'Tell me something funny!', 'Do you know a joke?'], 'responses': ['Why did the hipster burn his mouth? He drank the coffee before it was cool.', 'What did the buffalo say when his son left for college? Bison.']}\n",
            "{'tag': 'complaint', 'patterns': ['Your tea was awful', 'The coffee sucks', 'The tea I ordered was gross', 'I hated the coffee I bought from you', 'Your products are awful', 'Your store is terrible', 'The coffee I ordered tasted like garbage'], 'responses': [\"I'm sorry you did not like our product.\", \"I guess our store just isn't your cup of tea.\", \"I'm sorry you had a bad experience.\"]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_WmHEMELBJU"
      },
      "source": [
        "Because we have added a new intent, we need to retrain the model so it will learn the patterns associated with it and be able to recognize the new tag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpTt5s98IwHG",
        "outputId": "7b33f380-1635-46ed-e57c-1ee9e7a8d345"
      },
      "source": [
        "# Grab our JOSN file with the updated intents\n",
        "with open('chatbot_tutorial/intents.json') as f:\n",
        "  intents = json.load(f)\n",
        "\n",
        "# Process the data and set up the model like before\n",
        "all_words, tags, xy = process_training_data(intents)\n",
        "x_train, y_train = separate_train_x_y(all_words, tags, xy)\n",
        "dataset = ChatDataset(x_train, y_train)\n",
        "train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "model = NeuralNet(len(x_train[0]), hidden_size, len(tags)).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Retrain the model with the new data to incorporate the new intents\n",
        "train_model(model, train_loader, criterion, optimizer)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 100/1000, loss=1.3128\n",
            "epoch 200/1000, loss=0.1159\n",
            "epoch 300/1000, loss=0.0112\n",
            "epoch 400/1000, loss=0.0128\n",
            "epoch 500/1000, loss=0.0005\n",
            "epoch 600/1000, loss=0.0011\n",
            "epoch 700/1000, loss=0.0016\n",
            "epoch 800/1000, loss=0.0004\n",
            "epoch 900/1000, loss=0.0000\n",
            "epoch 1000/1000, loss=0.0004\n",
            "final loss=0.0004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ9CwxQSLP_a"
      },
      "source": [
        "Now try running the chatbot again, testing out your new intent!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A41JrCqiI9rb",
        "outputId": "4bb93de4-35dc-4d9f-9e14-e2a96b40b78a"
      },
      "source": [
        "run_chatbot()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's chat! Type 'quit' to exit\n",
            "You: hi\n",
            "Chatty: Hello, thanks for visiting\n",
            "You: what do you sell\n",
            "Chatty: We have coffee and tea\n",
            "You: I hated your tea\n",
            "Chatty: I guess our store just isn't your cup of tea.\n",
            "You: your coffee was terrible\n",
            "Chatty: I guess our store just isn't your cup of tea.\n",
            "You: when will my shipment arrive?\n",
            "Chatty: Hi there, how can I help?\n",
            "You: when will my delivery arrive?\n",
            "Chatty: Delivery takes 2-4 days\n",
            "You: I hated your products\n",
            "Chatty: I'm sorry you had a bad experience.\n",
            "You: byt\n",
            "Chatty: I do not understand :(\n",
            "You: bye\n",
            "Chatty: Have a nice day\n",
            "You: quit\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}