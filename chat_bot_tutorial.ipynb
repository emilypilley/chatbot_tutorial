{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chat_bot_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TTNDIRWrICeD",
        "xyxFnMoEIve6"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKyJTgBDk-a_"
      },
      "source": [
        "# Rule-Based Chatbot Tutorial\n",
        "* [Link to youtube playlist](https://youtu.be/RpWeNzfSUHw)\n",
        "* [Article with TF implementation](https://chatbotsmagazine.com/contextual-chat-bots-with-tensorflow-4391749d0077)\n",
        "\n",
        "**Overall Idea**: Our chatbot uses a model that is trained on cases of different intents (i.e. \"greeting\"), which is similar to a class label, and encompasses different patterns. There is a set of appropriate responses associated with each intent. \n",
        "\n",
        "However, you don't have to type the exact pattern in the training to get an appropriate response. The model predicts the intent of what the user wrote, and replies with an appropriate response for that intent. So, the chatbot can respond to whatever use cases you train the model on, and to extend the abilities of this chatbot, the model must be trained on additional intents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRwDaTb4A4Gv"
      },
      "source": [
        "###Relevant Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QUlw29nkQl_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f8c0df0-1071-4a54-f9c9-7731f877496b"
      },
      "source": [
        "from os import path\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x37BsJ_gk2DC"
      },
      "source": [
        "##  Step 1 - Data Processing Methods\n",
        "* Bag of words - the words from all the patterns are each represented by an inedex of a list (which contains all the words) and we represent each example patter in our training data as a vector (which contains indices for each word from the list) with 1's in the indices for words that are in this pattern and 0's in the indices for words that are not in this pattern\n",
        "\n",
        "How do we get this bag of words from the text of the patterns we write out? \n",
        "* tokenization - to split the text into individual words and punctuation\n",
        "* stemming - to get a general root of the word (ex: \"organize\", \"organizer\", and \"organizing\" all really mean the same thing)\n",
        "* We also want to make all the words lowercase and might want to get rid of punctuation too\n",
        "\n",
        "The NLTK library can help us do this!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJkQL_gmpgB0"
      },
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "def tokenize(sentence):\n",
        "  return nltk.word_tokenize(sentence)\n",
        "\n",
        "def stem(word):\n",
        "  return stemmer.stem(word.lower())\n",
        "\n",
        "def bag_of_words(tokenized_sentence, all_words):\n",
        "  tokenized_sentence = [stem(w) for w in tokenized_sentence]\n",
        "  bag = np.zeros(len(all_words), dtype=np.float32)\n",
        "\n",
        "  for idx, w in enumerate(all_words):\n",
        "    if w in tokenized_sentence:\n",
        "      bag[idx] = 1.0\n",
        "  \n",
        "  return bag"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqCrtgYLqaKw"
      },
      "source": [
        "### Examples of how these functions work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyHEAfaEqeTb",
        "outputId": "c182b397-b86e-457d-b873-44c40fa00531"
      },
      "source": [
        "sent_1 = \"Hi, nice to meet you! How are you doing?\"\n",
        "\n",
        "sent_1_tokenized = tokenize(sent_1)\n",
        "print(sent_1_tokenized)\n",
        "\n",
        "sent_1_stemmed = [stem(word) for word in sent_1_tokenized]\n",
        "print(sent_1_stemmed)\n",
        "\n",
        "# The words in the sentence above aren't very complicated,\n",
        "# so let's try another example to see how the stemmer works\n",
        "words_to_stem = ['organize', 'organizer', 'organizing'] \n",
        "stemmed_words = [stem(word) for word in words_to_stem]\n",
        "print(stemmed_words)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hi', ',', 'nice', 'to', 'meet', 'you', '!', 'How', 'are', 'you', 'doing', '?']\n",
            "['hi', ',', 'nice', 'to', 'meet', 'you', '!', 'how', 'are', 'you', 'do', '?']\n",
            "['organ', 'organ', 'organ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLRxgvlM98bQ"
      },
      "source": [
        "To test the bag_of_words function here, make sure you don't use punctuation and that the words in your sentence are in the word set. This is just for the example - these cases will be handled properly when we make the chatbot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgdPlGJc94ii",
        "outputId": "b35d8092-2f3f-4f93-bee7-cacfabe34c51"
      },
      "source": [
        "word_set = ['hi', 'hello', 'i', 'you', 'me', 'good', 'bad', 'nice', 'to', 'am', 'are', 'meet', 'do', 'it', 'when', 'how']\n",
        "sent_1_no_punc = \"Hi nice to meet you How are you doing\"\n",
        "\n",
        "sent_1_no_punc_tokenized = tokenize(sent_1_no_punc)\n",
        "sent_1_no_punc_stemmed = [stem(word) for word in sent_1_no_punc_tokenized]\n",
        "\n",
        "bag = bag_of_words(sent_1_no_punc_tokenized, word_set)\n",
        "print(bag)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQhsypFnsOP3"
      },
      "source": [
        "###**TODO:** Try adding your own sentence(s) and see how it is processed\n",
        "Add your text in parentheses and set it equal to \"sent_2\", and then run the cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kisSmJp2sMf3",
        "outputId": "67513ae8-2a1a-44a4-c0af-add2a2184409"
      },
      "source": [
        "sent_2 = \"Remove this text and add your own!\"\n",
        "\n",
        "sent_2_tokenized = tokenize(sent_2)\n",
        "print(sent_2_tokenized)\n",
        "\n",
        "sent_2_stemmed = [stem(word) for word in sent_2_tokenized]\n",
        "print(sent_2_stemmed)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Remove', 'this', 'text', 'and', 'add', 'your', 'own', '!']\n",
            "['remov', 'thi', 'text', 'and', 'add', 'your', 'own', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dYh32wQr433"
      },
      "source": [
        "##Step 2 - Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjWgjFHA4672"
      },
      "source": [
        "### Loading the Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWTx4ZWbBPL1"
      },
      "source": [
        "First we get a premade JSON file with some intents, patterns, and responses predefined"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRGMlNpN25cZ"
      },
      "source": [
        "if not path.exists('chatbot_tutorial'):\n",
        "  !git clone https://github.com/emilypilley/chatbot_tutorial.git"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKdfY39C3dZz",
        "outputId": "5b768b16-9c4b-4e4d-8f80-ef20a93d40bb"
      },
      "source": [
        "!ls chatbot_tutorial/"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "intents.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-1g13Hfr9ju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9424f6fa-11ad-413a-ebc2-6261a60602b5"
      },
      "source": [
        "# This opens the json file with our intents\n",
        "with open('chatbot_tutorial/intents.json') as f:\n",
        "  intents = json.load(f)\n",
        "\n",
        "print(intents)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'intents': [{'tag': 'greeting', 'patterns': ['Hi', 'Hey', 'How are you', 'Is anyone there?', 'Hello', 'Good day'], 'responses': ['Hey :-)', 'Hello, thanks for visiting', 'Hi there, what can I do for you?', 'Hi there, how can I help?']}, {'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye'], 'responses': ['See you later, thanks for visiting', 'Have a nice day', 'Bye! Come back again soon.']}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", \"Thank's a lot!\"], 'responses': ['Happy to help!', 'Any time!', 'My pleasure']}, {'tag': 'items', 'patterns': ['Which items do you have?', 'What kinds of items are there?', 'What do you sell?'], 'responses': ['We sell coffee and tea', 'We have coffee and tea']}, {'tag': 'payments', 'patterns': ['Do you take credit cards?', 'Do you accept Mastercard?', 'Can I pay with Paypal?', 'Are you cash only?'], 'responses': ['We accept VISA, Mastercard and Paypal', 'We accept most major credit cards, and Paypal']}, {'tag': 'delivery', 'patterns': ['How long does delivery take?', 'How long does shipping take?', 'When do I get my delivery?'], 'responses': ['Delivery takes 2-4 days', 'Shipping takes 2-4 days']}, {'tag': 'funny', 'patterns': ['Tell me a joke!', 'Tell me something funny!', 'Do you know a joke?'], 'responses': ['Why did the hipster burn his mouth? He drank the coffee before it was cool.', 'What did the buffalo say when his son left for college? Bison.']}, {'tag': 'tea_product_info', 'patterns': ['What kinds of tea do you have?', 'Which types of tea do you sell?', 'Tell me about the tea you have', 'What brands of tea do you carry?', 'Can you tell me more about your tea?', 'More info on tea', 'Do you have chamomile tea?', 'Do you sell herbal tea?'], 'responses': ['We sell green tea, matcha tea, chai tea, mint tea, and chamomile tea.', 'Our store carries green tea, matcha tea, chai tea, mint tea, and chamomile tea.', 'Our tea selection includes green tea, matcha tea, chai tea, mint tea, and chamomile tea.']}, {'tag': 'coffee_product_info', 'patterns': ['What kinds of coffee do you have?', 'Which types of coffee do you sell?', 'Tell me about the coffee you have', 'What brands of coffe do you carry?', 'Can you tell me more about your coffee?', 'More info on coffee', 'Do you have iced coffee?', 'Do you sell lattes?'], 'responses': ['We sell iced coffee, lattes, espressos, americanos, cappuccinos, and mochas.', 'Our store carries iced coffee, lattes, espressos, americanos, cappuccinos, and mochas.', 'Our tea selection includes iced coffee, lattes, espressos, americanos, cappuccinos, and mochas.']}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GoBt0sP5PZ6"
      },
      "source": [
        "### Processing the Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy2f6Unt6s2j"
      },
      "source": [
        "First, we apply the stemming and tokenization to the patterns from the training data, and remove punctuation and duplicate items, to get a set of all the words used in each pattern. We associate all the patterns for one tag with that tag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkzj3hI64z0D"
      },
      "source": [
        "def process_training_data(intents):\n",
        "  all_words = []\n",
        "  tags = []\n",
        "  xy = []  # holds patterns (x) and their assoicated tags (y)\n",
        "\n",
        "  for intent in intents['intents']:\n",
        "    tag = intent['tag']\n",
        "    tags.append(tag)\n",
        "\n",
        "    for pattern in intent['patterns']:\n",
        "      w = tokenize(pattern)\n",
        "      all_words.extend(w)\n",
        "      xy.append((w, tag))\n",
        "\n",
        "  ignore_words = ['?', '!', '.', ',']\n",
        "  all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
        "  all_words = sorted(set(all_words))\n",
        "  # print(all_words)\n",
        "\n",
        "  tags = sorted(set(tags))\n",
        "  # print(tags)\n",
        "\n",
        "  return tags, xy\n",
        "\n",
        "tags, xy = process_training_data(intents)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8eitZ72AvSp"
      },
      "source": [
        "### Preparing the Training Data for use with PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7fdFkt975q6"
      },
      "source": [
        "Then, we separate the data into x (the patterns) and y (the tag for the patterns) in order to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ctx3-fO07TzG"
      },
      "source": [
        "def separate_train_x_y(tags, xy):\n",
        "  x_train = []  # holds the patterns\n",
        "  y_train = []  # holds the tags for each pattern\n",
        "\n",
        "  for (pattern_sentence, tag) in xy:\n",
        "    bag = bag_of_words(pattern_sentence, all_words)\n",
        "    x_train.append(bag)\n",
        "\n",
        "    label = tags.index(tag)  # for the labels we are storing a number representing the tag\n",
        "    y_train.append(label)\n",
        "\n",
        "  x_train = np.array(x_train)\n",
        "  y_train = np.array(y_train)\n",
        "\n",
        "  return x_train, y_train\n",
        "\n",
        "x_train, y_train = separate_train_x_y(tags, xy)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsZd3vDpGgJp",
        "outputId": "a71ae5ab-64cc-44f2-f916-7b91bd126839"
      },
      "source": [
        "# this is the first pattern and its associated tag in the training data\n",
        "print(x_train[0])\n",
        "print(y_train[0])"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0.]\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03iYXTC__LcJ"
      },
      "source": [
        "Here we turn the data into PyTorch datasets (for use with the model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baoEqVkm_R1S"
      },
      "source": [
        "class ChatDataset(Dataset):\n",
        "  def __init__(self, x_train, y_train):\n",
        "    self.n_samples = len(x_train)\n",
        "    self.x_data = x_train\n",
        "    self.y_data = y_train\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    return self.x_data[index], self.y_data[index]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.n_samples"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0G_h0hRC7Ov"
      },
      "source": [
        "### Set the Hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDKFdmvr_-zF"
      },
      "source": [
        "Hyperparameters are aspects of the model that we can change that impact training - you can try to change some of these and see how this affects the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLPGH8wz_90S",
        "outputId": "6911d932-d0b3-4d85-bca4-1e20b56b23fe"
      },
      "source": [
        "# You can try adjusing the following by changing the numbers\n",
        "batch_size = 8\n",
        "hidden_size = 8\n",
        "learning_rate = 0.001\n",
        "num_epochs = 1000\n",
        "\n",
        "# These depend on our particular data - don't change!\n",
        "output_size = len(tags)\n",
        "input_size = len(x_train[0])\n",
        "\n",
        "print('output_size: ', output_size)\n",
        "print('input_size: ', input_size)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output_size:  9\n",
            "input_size:  54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wEIg6LkDA24"
      },
      "source": [
        "### Create the dataset and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeMTpvSj_x_2"
      },
      "source": [
        "dataset = ChatDataset(x_train, y_train)\n",
        "train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl3x2xGHGzGu",
        "outputId": "8451fd4f-3d1e-4fca-8376-2a98be70b11f"
      },
      "source": [
        "dataset.__getitem__(0)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0.], dtype=float32), 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dJAbqXxAgaH"
      },
      "source": [
        "## Step 3 - Create the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhn4M5bUCoJs"
      },
      "source": [
        "### Define the structure and flow of data through the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi-zEPmyAnVF"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  \n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet, self).__init__()\n",
        "\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.l2 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.l3 = nn.Linear(hidden_size, num_classes)\n",
        "    \n",
        "    self.relu = nn.ReLU()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    out = self.l2(out)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    out = self.l3(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUAYyaxgCip0"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = NeuralNet(input_size, hidden_size, output_size).to(device)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNDkFqqTEV70"
      },
      "source": [
        "Set loss function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D7cqfDsEUJQ"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_tX2DKjHpNS"
      },
      "source": [
        "###Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDd9FPxeEteL"
      },
      "source": [
        "Train the model to predict the tag based on the given input text (the patterns). This might take a minute, but you should be able to see the loss printed out after 100 epochs of training. Observe the loss function - it should be decreasing, indicating that the model is leraning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjxvQUSbEx9W",
        "outputId": "226f5d8e-245e-4ad9-a37e-49140ffef96b"
      },
      "source": [
        "def train_model(model, train_loader, loss_func, optimizer):\n",
        "  # training loop\n",
        "  for epoch in range(num_epochs):\n",
        "    for (words, labels) in train_loader:\n",
        "      words = words.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # forward pass\n",
        "      outputs = model(words)  # the outputs are the model's predictions\n",
        "      loss = loss_func(outputs, labels)\n",
        "\n",
        "      # backward and optimizer steps\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    \n",
        "    if (epoch + 1) % 100 == 0:\n",
        "      print(f'epoch {epoch+1}/{num_epochs}, loss={loss.item():.4f}')\n",
        "\n",
        "  print(f'final loss={loss.item():.4f}')\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "train_model(model, train_loader, criterion, optimizer)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 100/1000, loss=0.9335\n",
            "epoch 200/1000, loss=0.3809\n",
            "epoch 300/1000, loss=0.3667\n",
            "epoch 400/1000, loss=0.3772\n",
            "epoch 500/1000, loss=0.3621\n",
            "epoch 600/1000, loss=0.3192\n",
            "epoch 700/1000, loss=0.3370\n",
            "epoch 800/1000, loss=0.3427\n",
            "epoch 900/1000, loss=0.2918\n",
            "epoch 1000/1000, loss=0.3602\n",
            "final loss=0.3602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWgukQ52H9BT"
      },
      "source": [
        "## Step 4 - Save/Load Model and Implement Chatting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTNDIRWrICeD"
      },
      "source": [
        "### Save the model for later use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpWPIgIKHPgb",
        "outputId": "85a0a7af-2200-4968-ae4b-39fb81da1115"
      },
      "source": [
        "data = {\n",
        "    'model_state': model.state_dict(),\n",
        "    'input_size': input_size,\n",
        "    'output_size': output_size,\n",
        "    'hidden_size': hidden_size,\n",
        "    'all_words': all_words,\n",
        "    'tags': tags\n",
        "}\n",
        "\n",
        "FILE = 'data.pth'\n",
        "torch.save(data, FILE)\n",
        "\n",
        "print(f'training complete, file saved to {FILE}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training complete, file saved to data.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyxFnMoEIve6"
      },
      "source": [
        "### Run this if you have previously trained the model and saved it (and don't want to train it again)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSJ5nihVI0mS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "205a6e9d-4211-40b1-c992-3f4bec81713a"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "if not path.exists('chatbot_tutorial'):\n",
        "  !git clone https://github.com/emilypilley/chatbot_tutorial.git\n",
        "\n",
        "# This opens the json file with our intents\n",
        "with open('chatbot_tutorial/intents.json') as f:\n",
        "  intents = json.load(f)\n",
        "\n",
        "print(intents)\n",
        "\n",
        "FILE = 'data.pth'\n",
        "data = torch.load(FILE)\n",
        "\n",
        "input_size = data['input_size']\n",
        "output_size = data['output_size']\n",
        "hidden_size = data['hidden_size']\n",
        "\n",
        "all_words = data['all_words']\n",
        "tags = data['tags']\n",
        "model_state = data['model_state']\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
        "model.load_state_dict(model_state)\n",
        "\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'intents': [{'tag': 'greeting', 'patterns': ['Hi', 'Hey', 'How are you', 'Is anyone there?', 'Hello', 'Good day'], 'responses': ['Hey :-)', 'Hello, thanks for visiting', 'Hi there, what can I do for you?', 'Hi there, how can I help?']}, {'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye'], 'responses': ['See you later, thanks for visiting', 'Have a nice day', 'Bye! Come back again soon.']}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", \"Thank's a lot!\"], 'responses': ['Happy to help!', 'Any time!', 'My pleasure']}, {'tag': 'items', 'patterns': ['Which items do you have?', 'What kinds of items are there?', 'What do you sell?'], 'responses': ['We sell coffee and tea', 'We have coffee and tea']}, {'tag': 'payments', 'patterns': ['Do you take credit cards?', 'Do you accept Mastercard?', 'Can I pay with Paypal?', 'Are you cash only?'], 'responses': ['We accept VISA, Mastercard and Paypal', 'We accept most major credit cards, and Paypal']}, {'tag': 'delivery', 'patterns': ['How long does delivery take?', 'How long does shipping take?', 'When do I get my delivery?'], 'responses': ['Delivery takes 2-4 days', 'Shipping takes 2-4 days']}, {'tag': 'funny', 'patterns': ['Tell me a joke!', 'Tell me something funny!', 'Do you know a joke?'], 'responses': ['Why did the hipster burn his mouth? He drank the coffee before it was cool.', 'What did the buffalo say when his son left for college? Bison.']}]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNet(\n",
              "  (l1): Linear(in_features=54, out_features=8, bias=True)\n",
              "  (l2): Linear(in_features=8, out_features=8, bias=True)\n",
              "  (l3): Linear(in_features=8, out_features=7, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9upzO1tuLHu3"
      },
      "source": [
        "### Implement the Chatting Functionality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC6zF41QLLnn"
      },
      "source": [
        "def run_chatbot(bot_name='Chatty'):\n",
        "  print(\"Let's chat! Type 'quit' to exit\")\n",
        "\n",
        "  while True:\n",
        "    sentence = input('You: ')\n",
        "\n",
        "    if sentence == 'quit':\n",
        "      break\n",
        "    \n",
        "    # process the sentence the user inputs\n",
        "    sentence = [stem(word) for word in tokenize(sentence)]\n",
        "    x = bag_of_words(sentence, all_words)\n",
        "\n",
        "    # reshape and format the input data for the model\n",
        "    x = x.reshape(1, x.shape[0])\n",
        "    x = torch.from_numpy(x)\n",
        "\n",
        "    # get the predicted tag from the model\n",
        "    output = model(x)\n",
        "    _, predicted = torch.max(output, dim=1)\n",
        "    # the model outputs a number for the tag, this coverts it to\n",
        "    # the actual name of the tag\n",
        "    tag = tags[predicted.item()] \n",
        "\n",
        "    # the model will tell us how likely it is that the input \n",
        "    # sentence corresponds to a certain tag\n",
        "    probabilities = torch.softmax(output, dim=1)\n",
        "    probability = probabilities[0][predicted.item()]\n",
        "    print('tag: ', tag, ' probability: ', probability)\n",
        "    \n",
        "    if probability.item() > 0.75:\n",
        "      # find the corresponding intent for that tag\n",
        "      for intent in intents['intents']:\n",
        "        if tag == intent['tag']:\n",
        "          # the chatbot responds with one of the responses for \n",
        "          # the tag, randomly chosen from the possible responses\n",
        "          print(f\"{bot_name}: {random.choice(intent['responses'])}\") \n",
        "    \n",
        "    # if we couldn't determine what the intent of the sentence was \n",
        "    # with much certainty, the chatbot shouldn't respond\n",
        "    else:\n",
        "      print(f\"{bot_name}: I do not understand :(\") "
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMtmZMo6IN6E",
        "outputId": "9f74cab2-7482-43e2-cbcc-bd223ccc4385"
      },
      "source": [
        "run_chatbot()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's chat! Type 'quit' to exit\n",
            "You: hi\n",
            "Chatty: Hey :-)\n",
            "You: what do you sell?\n",
            "Chatty: We have coffee and tea\n",
            "You: tell me more about your tea\n",
            "Chatty: I do not understand :(\n",
            "You: tell me what tea you have\n",
            "Chatty: I do not understand :(\n",
            "You: what types of tea do you have\n",
            "Chatty: I do not understand :(\n",
            "You: tea info\n",
            "Chatty: I do not understand :(\n",
            "You: hi\n",
            "Chatty: Hey :-)\n",
            "You: tell me a joke\n",
            "Chatty: What did the buffalo say when his son left for college? Bison.\n",
            "You: how can I pay for an order?\n",
            "Chatty: I do not understand :(\n",
            "You: how long does delivery take?\n",
            "Chatty: Shipping takes 2-4 days\n",
            "You: are you cash only?\n",
            "Chatty: We accept most major credit cards, and Paypal\n",
            "You: how can I pay?\n",
            "Chatty: I do not understand :(\n",
            "You: quit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yasE79fWEfRS"
      },
      "source": [
        "## Step 5 - Adding New Intents and Patterns to Improve the Chatbot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iekew8D1Tcbp"
      },
      "source": [
        "### Implementation of functions to update JSON with new intents, print intents, and remove intents (given tag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zscz1oVCKsSa"
      },
      "source": [
        "These are functions to add the new intent to the JSON file holding all of the tags, patterns, and responses for each intent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRpTT147EjkE"
      },
      "source": [
        "def write_json(data, filename='chatbot_tutorial/intents.json'):\n",
        "    with open(filename,'w') as f:\n",
        "        json.dump(data, f, indent=4)\n",
        "      \n",
        "      \n",
        "def add_new_intent(tag, patterns, responses, filename='chatbot_tutorial/intents.json'):\n",
        "  with open('chatbot_tutorial/intents.json') as f:\n",
        "    data = json.load(f)\n",
        "      \n",
        "    intents = data['intents']\n",
        "  \n",
        "    new_intent = {\n",
        "      \"tag\": tag,\n",
        "      \"patterns\": patterns,\n",
        "      \"responses\": responses\n",
        "    }\n",
        "  \n",
        "    intents.append(new_intent)\n",
        "      \n",
        "  write_json(data, filename)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ee_RstHK2qq"
      },
      "source": [
        "If you want to check what intents are in the JSON file currently, run this method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGX8kMFqHYXm"
      },
      "source": [
        "def print_intents(filename='chatbot_tutorial/intents.json'):\n",
        "  with open('chatbot_tutorial/intents.json') as f:\n",
        "      data = json.load(f)\n",
        "        \n",
        "      intents = data['intents']\n",
        "      for intent in intents:\n",
        "        print(intent)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZa_Z7GPNH8x"
      },
      "source": [
        "If you want to remove an intent, just provide the tag to this method to delete it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zDNyu5OLtQ3"
      },
      "source": [
        "def remove_intent_with_tag(tag, filename='chatbot_tutorial/intents.json'):\n",
        "    with open('chatbot_tutorial/intents.json') as f:\n",
        "      data = json.load(f)\n",
        "      intents = data['intents']\n",
        "      for intent in intents:\n",
        "        if intent['tag'] == tag:\n",
        "          intents.remove(intent)\n",
        "\n",
        "    write_json(data, filename)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nnpk9OwuKdwh"
      },
      "source": [
        "### **TODO:** Fill in the tag, patterns, and responses as shown below with your new intent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTYsw-bBJ1KN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64ed0be8-d224-40aa-852c-df10195c9cbe"
      },
      "source": [
        "tag = \"tea_product_info\"\n",
        "\n",
        "patterns = [\n",
        "            \"What kinds of tea do you have?\",\n",
        "            \"Which types of tea do you sell?\",\n",
        "            \"Tell me about the tea you have\",\n",
        "            \"What brands of tea do you carry?\",\n",
        "            \"Can you tell me more about your tea?\",\n",
        "            \"More info on tea\",\n",
        "            \"Do you have chamomile tea?\",\n",
        "            \"Do you sell herbal tea?\"\n",
        "            ]\n",
        "\n",
        "responses =  [\n",
        "              \"We sell green tea, matcha tea, chai tea, mint tea, and chamomile tea.\",\n",
        "              \"Our store carries green tea, matcha tea, chai tea, mint tea, and chamomile tea.\",\n",
        "              \"Our tea selection includes green tea, matcha tea, chai tea, mint tea, and chamomile tea.\"\n",
        "              ]\n",
        "\n",
        "# This method adds the new intent\n",
        "add_new_intent(tag, patterns, responses)\n",
        "\n",
        "# Print out the intents to see that the file was updated with the new data\n",
        "print_intents()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'tag': 'greeting', 'patterns': ['Hi', 'Hey', 'How are you', 'Is anyone there?', 'Hello', 'Good day'], 'responses': ['Hey :-)', 'Hello, thanks for visiting', 'Hi there, what can I do for you?', 'Hi there, how can I help?']}\n",
            "{'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye'], 'responses': ['See you later, thanks for visiting', 'Have a nice day', 'Bye! Come back again soon.']}\n",
            "{'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", \"Thank's a lot!\"], 'responses': ['Happy to help!', 'Any time!', 'My pleasure']}\n",
            "{'tag': 'items', 'patterns': ['Which items do you have?', 'What kinds of items are there?', 'What do you sell?'], 'responses': ['We sell coffee and tea', 'We have coffee and tea']}\n",
            "{'tag': 'payments', 'patterns': ['Do you take credit cards?', 'Do you accept Mastercard?', 'Can I pay with Paypal?', 'Are you cash only?'], 'responses': ['We accept VISA, Mastercard and Paypal', 'We accept most major credit cards, and Paypal']}\n",
            "{'tag': 'delivery', 'patterns': ['How long does delivery take?', 'How long does shipping take?', 'When do I get my delivery?'], 'responses': ['Delivery takes 2-4 days', 'Shipping takes 2-4 days']}\n",
            "{'tag': 'funny', 'patterns': ['Tell me a joke!', 'Tell me something funny!', 'Do you know a joke?'], 'responses': ['Why did the hipster burn his mouth? He drank the coffee before it was cool.', 'What did the buffalo say when his son left for college? Bison.']}\n",
            "{'tag': 'tea_product_info', 'patterns': ['What kinds of tea do you have?', 'Which types of tea do you sell?', 'Tell me about the tea you have', 'What brands of tea do you carry?', 'Can you tell me more about your tea?', 'More info on tea', 'Do you have chamomile tea?', 'Do you sell herbal tea?'], 'responses': ['We sell green tea, matcha tea, chai tea, mint tea, and chamomile tea.', 'Our store carries green tea, matcha tea, chai tea, mint tea, and chamomile tea.', 'Our tea selection includes green tea, matcha tea, chai tea, mint tea, and chamomile tea.']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYUwwGIHUjpd",
        "outputId": "b9956f4c-d378-434c-fc75-e5863fb3131c"
      },
      "source": [
        "# tag_1 = \"coffee_product_info\"\n",
        "\n",
        "# patterns_1 = [\n",
        "#             \"What kinds of coffee do you have?\",\n",
        "#             \"Which types of coffee do you sell?\",\n",
        "#             \"Tell me about the coffee you have\",\n",
        "#             \"What brands of coffee do you carry?\",\n",
        "#             \"Can you tell me more about your coffee?\",\n",
        "#             \"More info on coffee\",\n",
        "#             \"Do you have iced coffee?\",\n",
        "#             \"Do you sell lattes?\"\n",
        "#             ]\n",
        "\n",
        "# responses_1 =  [\n",
        "#               \"We sell iced coffee, lattes, espressos, americanos, cappuccinos, and mochas.\",\n",
        "#               \"Our store carries iced coffee, lattes, espressos, americanos, cappuccinos, and mochas.\",\n",
        "#               \"Our tea selection includes iced coffee, lattes, espressos, americanos, cappuccinos, and mochas.\"\n",
        "#               ]\n",
        "\n",
        "# # This method adds the new intent\n",
        "# add_new_intent(tag_1, patterns_1, responses_1)\n",
        "\n",
        "# # Print out the intents to see that the file was updated with the new data\n",
        "# print_intents()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'tag': 'greeting', 'patterns': ['Hi', 'Hey', 'How are you', 'Is anyone there?', 'Hello', 'Good day'], 'responses': ['Hey :-)', 'Hello, thanks for visiting', 'Hi there, what can I do for you?', 'Hi there, how can I help?']}\n",
            "{'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye'], 'responses': ['See you later, thanks for visiting', 'Have a nice day', 'Bye! Come back again soon.']}\n",
            "{'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", \"Thank's a lot!\"], 'responses': ['Happy to help!', 'Any time!', 'My pleasure']}\n",
            "{'tag': 'items', 'patterns': ['Which items do you have?', 'What kinds of items are there?', 'What do you sell?'], 'responses': ['We sell coffee and tea', 'We have coffee and tea']}\n",
            "{'tag': 'payments', 'patterns': ['Do you take credit cards?', 'Do you accept Mastercard?', 'Can I pay with Paypal?', 'Are you cash only?'], 'responses': ['We accept VISA, Mastercard and Paypal', 'We accept most major credit cards, and Paypal']}\n",
            "{'tag': 'delivery', 'patterns': ['How long does delivery take?', 'How long does shipping take?', 'When do I get my delivery?'], 'responses': ['Delivery takes 2-4 days', 'Shipping takes 2-4 days']}\n",
            "{'tag': 'funny', 'patterns': ['Tell me a joke!', 'Tell me something funny!', 'Do you know a joke?'], 'responses': ['Why did the hipster burn his mouth? He drank the coffee before it was cool.', 'What did the buffalo say when his son left for college? Bison.']}\n",
            "{'tag': 'tea_product_info', 'patterns': ['What kinds of tea do you have?', 'Which types of tea do you sell?', 'Tell me about the tea you have', 'What brands of tea do you carry?', 'Can you tell me more about your tea?', 'More info on tea', 'Do you have chamomile tea?', 'Do you sell herbal tea?'], 'responses': ['We sell green tea, matcha tea, chai tea, mint tea, and chamomile tea.', 'Our store carries green tea, matcha tea, chai tea, mint tea, and chamomile tea.', 'Our tea selection includes green tea, matcha tea, chai tea, mint tea, and chamomile tea.']}\n",
            "{'tag': 'coffee_product_info', 'patterns': ['What kinds of coffee do you have?', 'Which types of coffee do you sell?', 'Tell me about the coffee you have', 'What brands of coffe do you carry?', 'Can you tell me more about your coffee?', 'More info on coffee', 'Do you have iced coffee?', 'Do you sell lattes?'], 'responses': ['We sell iced coffee, lattes, espressos, americanos, cappuccinos, and mochas.', 'Our store carries iced coffee, lattes, espressos, americanos, cappuccinos, and mochas.', 'Our tea selection includes iced coffee, lattes, espressos, americanos, cappuccinos, and mochas.']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_WmHEMELBJU"
      },
      "source": [
        "Because we have added a new intent, we need to retrain the model so it will learn the patterns associated with it and be able to recognize the new tag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpTt5s98IwHG",
        "outputId": "e4571e15-c459-4108-87db-58d728324f3a"
      },
      "source": [
        "# Grab our JOSN file with the updated intents\n",
        "with open('chatbot_tutorial/intents.json') as f:\n",
        "  intents = json.load(f)\n",
        "\n",
        "# Process the data and set up the model like before\n",
        "tags, xy = process_training_data(intents)\n",
        "x_train, y_train = separate_train_x_y(tags, xy)\n",
        "dataset = ChatDataset(x_train, y_train)\n",
        "train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "model = NeuralNet(len(x_train[0]), hidden_size, len(tags)).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Retrain the model with the new data to incorporate the new intents\n",
        "train_model(model, train_loader, criterion, optimizer)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 100/1000, loss=0.8133\n",
            "epoch 200/1000, loss=0.4199\n",
            "epoch 300/1000, loss=0.7143\n",
            "epoch 400/1000, loss=0.0052\n",
            "epoch 500/1000, loss=0.5659\n",
            "epoch 600/1000, loss=0.0195\n",
            "epoch 700/1000, loss=0.0007\n",
            "epoch 800/1000, loss=0.3520\n",
            "epoch 900/1000, loss=0.0028\n",
            "epoch 1000/1000, loss=0.3485\n",
            "final loss=0.3485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ9CwxQSLP_a"
      },
      "source": [
        "Now try running the chatbot again, testing out your new intent!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A41JrCqiI9rb",
        "outputId": "5607bbbd-1b19-4856-e9ab-3dd592ae11ad"
      },
      "source": [
        "run_chatbot()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's chat! Type 'quit' to exit\n",
            "You: hi\n",
            "tag:  greeting  probability:  tensor(0.9993, grad_fn=<SelectBackward>)\n",
            "Chatty: Hi there, what can I do for you?\n",
            "You: what do you sell\n",
            "tag:  items  probability:  tensor(0.9965, grad_fn=<SelectBackward>)\n",
            "Chatty: We have coffee and tea\n",
            "You: what types of coffee do you carry\n",
            "tag:  coffee_product_info  probability:  tensor(0.5004, grad_fn=<SelectBackward>)\n",
            "Chatty: I do not understand :(\n",
            "You: what types of tea do you carry\n",
            "tag:  coffee_product_info  probability:  tensor(0.5004, grad_fn=<SelectBackward>)\n",
            "Chatty: I do not understand :(\n",
            "You: tell me a joke\n",
            "tag:  funny  probability:  tensor(0.9992, grad_fn=<SelectBackward>)\n",
            "Chatty: Why did the hipster burn his mouth? He drank the coffee before it was cool.\n",
            "You: coffee info\n",
            "tag:  coffee_product_info  probability:  tensor(0.5083, grad_fn=<SelectBackward>)\n",
            "Chatty: I do not understand :(\n",
            "You: tea info\n",
            "tag:  coffee_product_info  probability:  tensor(0.5083, grad_fn=<SelectBackward>)\n",
            "Chatty: I do not understand :(\n",
            "You: what is up\n",
            "tag:  funny  probability:  tensor(0.5505, grad_fn=<SelectBackward>)\n",
            "Chatty: I do not understand :(\n",
            "You: howdy\n",
            "tag:  coffee_product_info  probability:  tensor(0.5083, grad_fn=<SelectBackward>)\n",
            "Chatty: I do not understand :(\n",
            "You: quit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GusLHyt8LYXp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}